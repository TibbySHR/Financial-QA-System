{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7873100983020556,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008936550491510277,
      "grad_norm": 6.23656702041626,
      "learning_rate": 4.999890527784777e-05,
      "loss": 2.6266,
      "step": 10
    },
    {
      "epoch": 0.017873100983020553,
      "grad_norm": 3.7578649520874023,
      "learning_rate": 4.9995621207264426e-05,
      "loss": 1.2134,
      "step": 20
    },
    {
      "epoch": 0.02680965147453083,
      "grad_norm": 2.3817241191864014,
      "learning_rate": 4.999014807586154e-05,
      "loss": 0.2962,
      "step": 30
    },
    {
      "epoch": 0.035746201966041107,
      "grad_norm": 0.48485124111175537,
      "learning_rate": 4.998248636296377e-05,
      "loss": 0.22,
      "step": 40
    },
    {
      "epoch": 0.044682752457551385,
      "grad_norm": 0.17463254928588867,
      "learning_rate": 4.997263673956685e-05,
      "loss": 0.0964,
      "step": 50
    },
    {
      "epoch": 0.05361930294906166,
      "grad_norm": 0.11658822745084763,
      "learning_rate": 4.9960600068278876e-05,
      "loss": 0.0385,
      "step": 60
    },
    {
      "epoch": 0.06255585344057193,
      "grad_norm": 4.277348518371582,
      "learning_rate": 4.9946377403244695e-05,
      "loss": 0.1256,
      "step": 70
    },
    {
      "epoch": 0.07149240393208221,
      "grad_norm": 0.20031121373176575,
      "learning_rate": 4.992996999005363e-05,
      "loss": 0.4709,
      "step": 80
    },
    {
      "epoch": 0.08042895442359249,
      "grad_norm": 3.630690336227417,
      "learning_rate": 4.991137926563036e-05,
      "loss": 0.0723,
      "step": 90
    },
    {
      "epoch": 0.08936550491510277,
      "grad_norm": 0.907142698764801,
      "learning_rate": 4.9890606858109126e-05,
      "loss": 0.12,
      "step": 100
    },
    {
      "epoch": 0.09830205540661305,
      "grad_norm": 0.12208512425422668,
      "learning_rate": 4.98676545866911e-05,
      "loss": 0.15,
      "step": 110
    },
    {
      "epoch": 0.10723860589812333,
      "grad_norm": 2.905740737915039,
      "learning_rate": 4.984252446148508e-05,
      "loss": 0.0903,
      "step": 120
    },
    {
      "epoch": 0.1161751563896336,
      "grad_norm": 2.483842611312866,
      "learning_rate": 4.981521868333144e-05,
      "loss": 0.2155,
      "step": 130
    },
    {
      "epoch": 0.12511170688114387,
      "grad_norm": 0.08467451483011246,
      "learning_rate": 4.9785739643609406e-05,
      "loss": 0.0695,
      "step": 140
    },
    {
      "epoch": 0.13404825737265416,
      "grad_norm": 5.0849480628967285,
      "learning_rate": 4.97540899240276e-05,
      "loss": 0.1769,
      "step": 150
    },
    {
      "epoch": 0.14298480786416443,
      "grad_norm": 1.984716534614563,
      "learning_rate": 4.9720272296397946e-05,
      "loss": 0.0452,
      "step": 160
    },
    {
      "epoch": 0.15192135835567472,
      "grad_norm": 3.0237185955047607,
      "learning_rate": 4.968428972239294e-05,
      "loss": 0.1416,
      "step": 170
    },
    {
      "epoch": 0.16085790884718498,
      "grad_norm": 0.13628481328487396,
      "learning_rate": 4.964614535328626e-05,
      "loss": 0.1695,
      "step": 180
    },
    {
      "epoch": 0.16979445933869527,
      "grad_norm": 0.5326299667358398,
      "learning_rate": 4.9605842529676746e-05,
      "loss": 0.1728,
      "step": 190
    },
    {
      "epoch": 0.17873100983020554,
      "grad_norm": 2.874516487121582,
      "learning_rate": 4.956338478119592e-05,
      "loss": 0.1326,
      "step": 200
    },
    {
      "epoch": 0.1876675603217158,
      "grad_norm": 0.5344688296318054,
      "learning_rate": 4.951877582619881e-05,
      "loss": 0.1521,
      "step": 210
    },
    {
      "epoch": 0.1966041108132261,
      "grad_norm": 0.4228476583957672,
      "learning_rate": 4.947201957143831e-05,
      "loss": 0.2703,
      "step": 220
    },
    {
      "epoch": 0.20554066130473636,
      "grad_norm": 3.9370229244232178,
      "learning_rate": 4.942312011172304e-05,
      "loss": 0.1879,
      "step": 230
    },
    {
      "epoch": 0.21447721179624665,
      "grad_norm": 5.221630573272705,
      "learning_rate": 4.937208172955876e-05,
      "loss": 0.075,
      "step": 240
    },
    {
      "epoch": 0.22341376228775692,
      "grad_norm": 0.038582686334848404,
      "learning_rate": 4.931890889477325e-05,
      "loss": 0.1558,
      "step": 250
    },
    {
      "epoch": 0.2323503127792672,
      "grad_norm": 0.3536983132362366,
      "learning_rate": 4.926360626412494e-05,
      "loss": 0.1093,
      "step": 260
    },
    {
      "epoch": 0.24128686327077747,
      "grad_norm": 1.3568994998931885,
      "learning_rate": 4.920617868089501e-05,
      "loss": 0.0998,
      "step": 270
    },
    {
      "epoch": 0.25022341376228774,
      "grad_norm": 0.04528854787349701,
      "learning_rate": 4.914663117446327e-05,
      "loss": 0.0177,
      "step": 280
    },
    {
      "epoch": 0.25915996425379806,
      "grad_norm": 0.027410218492150307,
      "learning_rate": 4.908496895986765e-05,
      "loss": 0.1493,
      "step": 290
    },
    {
      "epoch": 0.2680965147453083,
      "grad_norm": 2.0073676109313965,
      "learning_rate": 4.9021197437347555e-05,
      "loss": 0.2186,
      "step": 300
    },
    {
      "epoch": 0.2770330652368186,
      "grad_norm": 5.989713191986084,
      "learning_rate": 4.895532219187085e-05,
      "loss": 0.1931,
      "step": 310
    },
    {
      "epoch": 0.28596961572832885,
      "grad_norm": 1.5917341709136963,
      "learning_rate": 4.888734899264477e-05,
      "loss": 0.0878,
      "step": 320
    },
    {
      "epoch": 0.2949061662198391,
      "grad_norm": 2.178004264831543,
      "learning_rate": 4.881728379261068e-05,
      "loss": 0.2108,
      "step": 330
    },
    {
      "epoch": 0.30384271671134944,
      "grad_norm": 0.03521766513586044,
      "learning_rate": 4.8745132727922696e-05,
      "loss": 0.4201,
      "step": 340
    },
    {
      "epoch": 0.3127792672028597,
      "grad_norm": 0.036882348358631134,
      "learning_rate": 4.867090211741033e-05,
      "loss": 0.1021,
      "step": 350
    },
    {
      "epoch": 0.32171581769436997,
      "grad_norm": 0.2642865777015686,
      "learning_rate": 4.859459846202507e-05,
      "loss": 0.041,
      "step": 360
    },
    {
      "epoch": 0.33065236818588023,
      "grad_norm": 0.04429810494184494,
      "learning_rate": 4.851622844427107e-05,
      "loss": 0.0132,
      "step": 370
    },
    {
      "epoch": 0.33958891867739055,
      "grad_norm": 0.3786800503730774,
      "learning_rate": 4.84357989276199e-05,
      "loss": 0.0307,
      "step": 380
    },
    {
      "epoch": 0.3485254691689008,
      "grad_norm": 0.00892890989780426,
      "learning_rate": 4.835331695590943e-05,
      "loss": 0.058,
      "step": 390
    },
    {
      "epoch": 0.3574620196604111,
      "grad_norm": 4.418198585510254,
      "learning_rate": 4.8268789752726993e-05,
      "loss": 0.0805,
      "step": 400
    },
    {
      "epoch": 0.36639857015192134,
      "grad_norm": 0.029284076765179634,
      "learning_rate": 4.818222472077674e-05,
      "loss": 0.0822,
      "step": 410
    },
    {
      "epoch": 0.3753351206434316,
      "grad_norm": 0.01240680180490017,
      "learning_rate": 4.809362944123129e-05,
      "loss": 0.0855,
      "step": 420
    },
    {
      "epoch": 0.38427167113494193,
      "grad_norm": 0.9219762086868286,
      "learning_rate": 4.800301167306789e-05,
      "loss": 0.2612,
      "step": 430
    },
    {
      "epoch": 0.3932082216264522,
      "grad_norm": 6.82234525680542,
      "learning_rate": 4.791037935238877e-05,
      "loss": 0.1107,
      "step": 440
    },
    {
      "epoch": 0.40214477211796246,
      "grad_norm": 3.794564962387085,
      "learning_rate": 4.781574059172621e-05,
      "loss": 0.0206,
      "step": 450
    },
    {
      "epoch": 0.4110813226094727,
      "grad_norm": 0.14708811044692993,
      "learning_rate": 4.771910367933204e-05,
      "loss": 0.1245,
      "step": 460
    },
    {
      "epoch": 0.42001787310098304,
      "grad_norm": 0.03326249495148659,
      "learning_rate": 4.762047707845175e-05,
      "loss": 0.0154,
      "step": 470
    },
    {
      "epoch": 0.4289544235924933,
      "grad_norm": 0.029325325042009354,
      "learning_rate": 4.751986942658332e-05,
      "loss": 0.1193,
      "step": 480
    },
    {
      "epoch": 0.43789097408400357,
      "grad_norm": 0.13973990082740784,
      "learning_rate": 4.7417289534720774e-05,
      "loss": 0.1316,
      "step": 490
    },
    {
      "epoch": 0.44682752457551383,
      "grad_norm": 3.979116678237915,
      "learning_rate": 4.731274638658251e-05,
      "loss": 0.0971,
      "step": 500
    },
    {
      "epoch": 0.45576407506702415,
      "grad_norm": 0.002255219267681241,
      "learning_rate": 4.7206249137824535e-05,
      "loss": 0.0252,
      "step": 510
    },
    {
      "epoch": 0.4647006255585344,
      "grad_norm": 7.863351345062256,
      "learning_rate": 4.709780711523862e-05,
      "loss": 0.1435,
      "step": 520
    },
    {
      "epoch": 0.4736371760500447,
      "grad_norm": 0.9248009324073792,
      "learning_rate": 4.698742981593555e-05,
      "loss": 0.0808,
      "step": 530
    },
    {
      "epoch": 0.48257372654155495,
      "grad_norm": 2.7815282344818115,
      "learning_rate": 4.687512690651328e-05,
      "loss": 0.113,
      "step": 540
    },
    {
      "epoch": 0.4915102770330652,
      "grad_norm": 0.020158834755420685,
      "learning_rate": 4.676090822221042e-05,
      "loss": 0.0701,
      "step": 550
    },
    {
      "epoch": 0.5004468275245755,
      "grad_norm": 0.019986821338534355,
      "learning_rate": 4.664478376604488e-05,
      "loss": 0.1347,
      "step": 560
    },
    {
      "epoch": 0.5093833780160858,
      "grad_norm": 0.022473573684692383,
      "learning_rate": 4.652676370793784e-05,
      "loss": 0.0111,
      "step": 570
    },
    {
      "epoch": 0.5183199285075961,
      "grad_norm": 0.016895929351449013,
      "learning_rate": 4.6406858383823056e-05,
      "loss": 0.0562,
      "step": 580
    },
    {
      "epoch": 0.5272564789991063,
      "grad_norm": 2.9193077087402344,
      "learning_rate": 4.628507829474168e-05,
      "loss": 0.2227,
      "step": 590
    },
    {
      "epoch": 0.5361930294906166,
      "grad_norm": 0.045295339077711105,
      "learning_rate": 4.6161434105922616e-05,
      "loss": 0.0608,
      "step": 600
    },
    {
      "epoch": 0.5451295799821269,
      "grad_norm": 0.04284278675913811,
      "learning_rate": 4.6035936645848476e-05,
      "loss": 0.0197,
      "step": 610
    },
    {
      "epoch": 0.5540661304736372,
      "grad_norm": 6.882468223571777,
      "learning_rate": 4.59085969053072e-05,
      "loss": 0.3312,
      "step": 620
    },
    {
      "epoch": 0.5630026809651475,
      "grad_norm": 0.5764377117156982,
      "learning_rate": 4.577942603642959e-05,
      "loss": 0.1279,
      "step": 630
    },
    {
      "epoch": 0.5719392314566577,
      "grad_norm": 0.008499832823872566,
      "learning_rate": 4.564843535171257e-05,
      "loss": 0.0879,
      "step": 640
    },
    {
      "epoch": 0.580875781948168,
      "grad_norm": 0.03177427127957344,
      "learning_rate": 4.551563632302849e-05,
      "loss": 0.0726,
      "step": 650
    },
    {
      "epoch": 0.5898123324396782,
      "grad_norm": 0.2588426470756531,
      "learning_rate": 4.538104058062042e-05,
      "loss": 0.1283,
      "step": 660
    },
    {
      "epoch": 0.5987488829311886,
      "grad_norm": 0.0656043142080307,
      "learning_rate": 4.5244659912083626e-05,
      "loss": 0.1233,
      "step": 670
    },
    {
      "epoch": 0.6076854334226989,
      "grad_norm": 0.2656986117362976,
      "learning_rate": 4.5106506261333234e-05,
      "loss": 0.073,
      "step": 680
    },
    {
      "epoch": 0.6166219839142091,
      "grad_norm": 0.012457868084311485,
      "learning_rate": 4.4966591727558184e-05,
      "loss": 0.1285,
      "step": 690
    },
    {
      "epoch": 0.6255585344057194,
      "grad_norm": 0.021048851311206818,
      "learning_rate": 4.482492856416165e-05,
      "loss": 0.0379,
      "step": 700
    },
    {
      "epoch": 0.6344950848972297,
      "grad_norm": 2.324502944946289,
      "learning_rate": 4.4681529177687876e-05,
      "loss": 0.0107,
      "step": 710
    },
    {
      "epoch": 0.6434316353887399,
      "grad_norm": 8.935158729553223,
      "learning_rate": 4.4536406126735664e-05,
      "loss": 0.0727,
      "step": 720
    },
    {
      "epoch": 0.6523681858802503,
      "grad_norm": 5.777193069458008,
      "learning_rate": 4.4389572120858506e-05,
      "loss": 0.0748,
      "step": 730
    },
    {
      "epoch": 0.6613047363717605,
      "grad_norm": 0.13298848271369934,
      "learning_rate": 4.424104001945151e-05,
      "loss": 0.0859,
      "step": 740
    },
    {
      "epoch": 0.6702412868632708,
      "grad_norm": 4.593738555908203,
      "learning_rate": 4.4090822830625236e-05,
      "loss": 0.1793,
      "step": 750
    },
    {
      "epoch": 0.6791778373547811,
      "grad_norm": 0.2716250419616699,
      "learning_rate": 4.3938933710066396e-05,
      "loss": 0.0558,
      "step": 760
    },
    {
      "epoch": 0.6881143878462913,
      "grad_norm": 0.10478967428207397,
      "learning_rate": 4.3785385959885805e-05,
      "loss": 0.0302,
      "step": 770
    },
    {
      "epoch": 0.6970509383378016,
      "grad_norm": 1.637869954109192,
      "learning_rate": 4.363019302745334e-05,
      "loss": 0.0451,
      "step": 780
    },
    {
      "epoch": 0.7059874888293118,
      "grad_norm": 0.03528118133544922,
      "learning_rate": 4.347336850422029e-05,
      "loss": 0.0464,
      "step": 790
    },
    {
      "epoch": 0.7149240393208222,
      "grad_norm": 3.0347554683685303,
      "learning_rate": 4.331492612452901e-05,
      "loss": 0.0661,
      "step": 800
    },
    {
      "epoch": 0.7238605898123325,
      "grad_norm": 2.357445001602173,
      "learning_rate": 4.315487976441014e-05,
      "loss": 0.2275,
      "step": 810
    },
    {
      "epoch": 0.7327971403038427,
      "grad_norm": 0.06598158925771713,
      "learning_rate": 4.2993243440367345e-05,
      "loss": 0.0996,
      "step": 820
    },
    {
      "epoch": 0.741733690795353,
      "grad_norm": 2.4914889335632324,
      "learning_rate": 4.283003130814978e-05,
      "loss": 0.1406,
      "step": 830
    },
    {
      "epoch": 0.7506702412868632,
      "grad_norm": 0.02737709879875183,
      "learning_rate": 4.266525766151238e-05,
      "loss": 0.0474,
      "step": 840
    },
    {
      "epoch": 0.7596067917783735,
      "grad_norm": 1.1837223768234253,
      "learning_rate": 4.249893693096404e-05,
      "loss": 0.1236,
      "step": 850
    },
    {
      "epoch": 0.7685433422698839,
      "grad_norm": 0.04914654791355133,
      "learning_rate": 4.23310836825038e-05,
      "loss": 0.1267,
      "step": 860
    },
    {
      "epoch": 0.7774798927613941,
      "grad_norm": 0.03842444345355034,
      "learning_rate": 4.216171261634521e-05,
      "loss": 0.0568,
      "step": 870
    },
    {
      "epoch": 0.7864164432529044,
      "grad_norm": 0.39606237411499023,
      "learning_rate": 4.199083856562893e-05,
      "loss": 0.1723,
      "step": 880
    },
    {
      "epoch": 0.7953529937444147,
      "grad_norm": 3.5832080841064453,
      "learning_rate": 4.181847649512362e-05,
      "loss": 0.042,
      "step": 890
    },
    {
      "epoch": 0.8042895442359249,
      "grad_norm": 0.08711913228034973,
      "learning_rate": 4.1644641499915454e-05,
      "loss": 0.0914,
      "step": 900
    },
    {
      "epoch": 0.8132260947274352,
      "grad_norm": 0.021631838753819466,
      "learning_rate": 4.1469348804086016e-05,
      "loss": 0.0135,
      "step": 910
    },
    {
      "epoch": 0.8221626452189454,
      "grad_norm": 2.544900417327881,
      "learning_rate": 4.12926137593791e-05,
      "loss": 0.1476,
      "step": 920
    },
    {
      "epoch": 0.8310991957104558,
      "grad_norm": 0.4034262001514435,
      "learning_rate": 4.111445184385616e-05,
      "loss": 0.0871,
      "step": 930
    },
    {
      "epoch": 0.8400357462019661,
      "grad_norm": 0.05324997007846832,
      "learning_rate": 4.093487866054088e-05,
      "loss": 0.074,
      "step": 940
    },
    {
      "epoch": 0.8489722966934763,
      "grad_norm": 3.087310552597046,
      "learning_rate": 4.075390993605258e-05,
      "loss": 0.0635,
      "step": 950
    },
    {
      "epoch": 0.8579088471849866,
      "grad_norm": 0.3823474049568176,
      "learning_rate": 4.0571561519228984e-05,
      "loss": 0.1184,
      "step": 960
    },
    {
      "epoch": 0.8668453976764968,
      "grad_norm": 0.10512351244688034,
      "learning_rate": 4.03878493797382e-05,
      "loss": 0.0955,
      "step": 970
    },
    {
      "epoch": 0.8757819481680071,
      "grad_norm": 2.2664458751678467,
      "learning_rate": 4.0202789606680136e-05,
      "loss": 0.0925,
      "step": 980
    },
    {
      "epoch": 0.8847184986595175,
      "grad_norm": 2.6446683406829834,
      "learning_rate": 4.001639840717741e-05,
      "loss": 0.053,
      "step": 990
    },
    {
      "epoch": 0.8936550491510277,
      "grad_norm": 2.944815158843994,
      "learning_rate": 3.9828692104956054e-05,
      "loss": 0.0815,
      "step": 1000
    },
    {
      "epoch": 0.902591599642538,
      "grad_norm": 3.307349443435669,
      "learning_rate": 3.963968713891584e-05,
      "loss": 0.0848,
      "step": 1010
    },
    {
      "epoch": 0.9115281501340483,
      "grad_norm": 2.510632276535034,
      "learning_rate": 3.94494000616906e-05,
      "loss": 0.0211,
      "step": 1020
    },
    {
      "epoch": 0.9204647006255585,
      "grad_norm": 4.001150608062744,
      "learning_rate": 3.9257847538198654e-05,
      "loss": 0.0759,
      "step": 1030
    },
    {
      "epoch": 0.9294012511170688,
      "grad_norm": 0.17544305324554443,
      "learning_rate": 3.9065046344183265e-05,
      "loss": 0.0468,
      "step": 1040
    },
    {
      "epoch": 0.938337801608579,
      "grad_norm": 0.023284096270799637,
      "learning_rate": 3.887101336474346e-05,
      "loss": 0.0056,
      "step": 1050
    },
    {
      "epoch": 0.9472743521000894,
      "grad_norm": 0.06917548179626465,
      "learning_rate": 3.867576559285533e-05,
      "loss": 0.0345,
      "step": 1060
    },
    {
      "epoch": 0.9562109025915997,
      "grad_norm": 3.238286018371582,
      "learning_rate": 3.8479320127883744e-05,
      "loss": 0.0781,
      "step": 1070
    },
    {
      "epoch": 0.9651474530831099,
      "grad_norm": 1.8043055534362793,
      "learning_rate": 3.828169417408488e-05,
      "loss": 0.0392,
      "step": 1080
    },
    {
      "epoch": 0.9740840035746202,
      "grad_norm": 0.0018522851169109344,
      "learning_rate": 3.8082905039099496e-05,
      "loss": 0.0355,
      "step": 1090
    },
    {
      "epoch": 0.9830205540661304,
      "grad_norm": 1.397919774055481,
      "learning_rate": 3.788297013243718e-05,
      "loss": 0.2022,
      "step": 1100
    },
    {
      "epoch": 0.9919571045576407,
      "grad_norm": 0.013538000173866749,
      "learning_rate": 3.768190696395162e-05,
      "loss": 0.0776,
      "step": 1110
    },
    {
      "epoch": 1.000893655049151,
      "grad_norm": 0.009137693792581558,
      "learning_rate": 3.74797331423072e-05,
      "loss": 0.2769,
      "step": 1120
    },
    {
      "epoch": 1.0098302055406614,
      "grad_norm": 0.013425849378108978,
      "learning_rate": 3.727646637343678e-05,
      "loss": 0.0111,
      "step": 1130
    },
    {
      "epoch": 1.0187667560321716,
      "grad_norm": 0.07761355489492416,
      "learning_rate": 3.707212445899116e-05,
      "loss": 0.068,
      "step": 1140
    },
    {
      "epoch": 1.0277033065236818,
      "grad_norm": 1.3910585641860962,
      "learning_rate": 3.686672529477998e-05,
      "loss": 0.0204,
      "step": 1150
    },
    {
      "epoch": 1.0366398570151922,
      "grad_norm": 0.23201480507850647,
      "learning_rate": 3.666028686920443e-05,
      "loss": 0.0074,
      "step": 1160
    },
    {
      "epoch": 1.0455764075067024,
      "grad_norm": 2.649838447570801,
      "learning_rate": 3.645282726168191e-05,
      "loss": 0.0317,
      "step": 1170
    },
    {
      "epoch": 1.0545129579982127,
      "grad_norm": 4.052329063415527,
      "learning_rate": 3.624436464106267e-05,
      "loss": 0.0788,
      "step": 1180
    },
    {
      "epoch": 1.063449508489723,
      "grad_norm": 0.08869221061468124,
      "learning_rate": 3.603491726403862e-05,
      "loss": 0.0772,
      "step": 1190
    },
    {
      "epoch": 1.0723860589812333,
      "grad_norm": 0.5324770212173462,
      "learning_rate": 3.5824503473544405e-05,
      "loss": 0.0921,
      "step": 1200
    },
    {
      "epoch": 1.0813226094727435,
      "grad_norm": 0.04323594272136688,
      "learning_rate": 3.5613141697151055e-05,
      "loss": 0.0095,
      "step": 1210
    },
    {
      "epoch": 1.0902591599642537,
      "grad_norm": 2.297600030899048,
      "learning_rate": 3.540085044545205e-05,
      "loss": 0.0489,
      "step": 1220
    },
    {
      "epoch": 1.0991957104557641,
      "grad_norm": 0.03543649986386299,
      "learning_rate": 3.518764831044228e-05,
      "loss": 0.0326,
      "step": 1230
    },
    {
      "epoch": 1.1081322609472744,
      "grad_norm": 0.13693886995315552,
      "learning_rate": 3.497355396388974e-05,
      "loss": 0.0479,
      "step": 1240
    },
    {
      "epoch": 1.1170688114387846,
      "grad_norm": 6.522353649139404,
      "learning_rate": 3.475858615570035e-05,
      "loss": 0.0914,
      "step": 1250
    },
    {
      "epoch": 1.126005361930295,
      "grad_norm": 9.165407180786133,
      "learning_rate": 3.4542763712275836e-05,
      "loss": 0.1614,
      "step": 1260
    },
    {
      "epoch": 1.1349419124218052,
      "grad_norm": 0.012278449721634388,
      "learning_rate": 3.432610553486497e-05,
      "loss": 0.0331,
      "step": 1270
    },
    {
      "epoch": 1.1438784629133154,
      "grad_norm": 5.1987223625183105,
      "learning_rate": 3.410863059790827e-05,
      "loss": 0.0511,
      "step": 1280
    },
    {
      "epoch": 1.1528150134048256,
      "grad_norm": 0.0157734714448452,
      "learning_rate": 3.3890357947376216e-05,
      "loss": 0.0456,
      "step": 1290
    },
    {
      "epoch": 1.161751563896336,
      "grad_norm": 0.14864370226860046,
      "learning_rate": 3.3671306699101266e-05,
      "loss": 0.0039,
      "step": 1300
    },
    {
      "epoch": 1.1706881143878463,
      "grad_norm": 0.016777126118540764,
      "learning_rate": 3.345149603710373e-05,
      "loss": 0.0647,
      "step": 1310
    },
    {
      "epoch": 1.1796246648793565,
      "grad_norm": 0.21899330615997314,
      "learning_rate": 3.323094521191169e-05,
      "loss": 0.0706,
      "step": 1320
    },
    {
      "epoch": 1.188561215370867,
      "grad_norm": 0.01869368925690651,
      "learning_rate": 3.300967353887507e-05,
      "loss": 0.0059,
      "step": 1330
    },
    {
      "epoch": 1.197497765862377,
      "grad_norm": 0.004086640663444996,
      "learning_rate": 3.278770039647406e-05,
      "loss": 0.0127,
      "step": 1340
    },
    {
      "epoch": 1.2064343163538873,
      "grad_norm": 0.023097801953554153,
      "learning_rate": 3.2565045224621923e-05,
      "loss": 0.0233,
      "step": 1350
    },
    {
      "epoch": 1.2153708668453977,
      "grad_norm": 0.8140990734100342,
      "learning_rate": 3.234172752296259e-05,
      "loss": 0.1003,
      "step": 1360
    },
    {
      "epoch": 1.224307417336908,
      "grad_norm": 0.005656220950186253,
      "learning_rate": 3.2117766849162855e-05,
      "loss": 0.1978,
      "step": 1370
    },
    {
      "epoch": 1.2332439678284182,
      "grad_norm": 0.043619606643915176,
      "learning_rate": 3.189318281719959e-05,
      "loss": 0.0474,
      "step": 1380
    },
    {
      "epoch": 1.2421805183199286,
      "grad_norm": 0.03250546008348465,
      "learning_rate": 3.1667995095641975e-05,
      "loss": 0.0728,
      "step": 1390
    },
    {
      "epoch": 1.2511170688114388,
      "grad_norm": 4.373394012451172,
      "learning_rate": 3.1442223405928985e-05,
      "loss": 0.0919,
      "step": 1400
    },
    {
      "epoch": 1.260053619302949,
      "grad_norm": 0.04062284156680107,
      "learning_rate": 3.1215887520642237e-05,
      "loss": 0.0261,
      "step": 1410
    },
    {
      "epoch": 1.2689901697944594,
      "grad_norm": 0.014213476330041885,
      "learning_rate": 3.098900726177432e-05,
      "loss": 0.0297,
      "step": 1420
    },
    {
      "epoch": 1.2779267202859697,
      "grad_norm": 0.7330724596977234,
      "learning_rate": 3.076160249899286e-05,
      "loss": 0.1087,
      "step": 1430
    },
    {
      "epoch": 1.2868632707774799,
      "grad_norm": 0.009581220336258411,
      "learning_rate": 3.0533693147900365e-05,
      "loss": 0.0289,
      "step": 1440
    },
    {
      "epoch": 1.2957998212689903,
      "grad_norm": 0.1957419514656067,
      "learning_rate": 3.0305299168290064e-05,
      "loss": 0.0583,
      "step": 1450
    },
    {
      "epoch": 1.3047363717605005,
      "grad_norm": 4.706699371337891,
      "learning_rate": 3.0076440562397857e-05,
      "loss": 0.0736,
      "step": 1460
    },
    {
      "epoch": 1.3136729222520107,
      "grad_norm": 0.009853099472820759,
      "learning_rate": 2.9847137373150602e-05,
      "loss": 0.1582,
      "step": 1470
    },
    {
      "epoch": 1.322609472743521,
      "grad_norm": 0.015778444707393646,
      "learning_rate": 2.961740968241077e-05,
      "loss": 0.0672,
      "step": 1480
    },
    {
      "epoch": 1.3315460232350314,
      "grad_norm": 0.8583592176437378,
      "learning_rate": 2.9387277609217713e-05,
      "loss": 0.0429,
      "step": 1490
    },
    {
      "epoch": 1.3404825737265416,
      "grad_norm": 0.015067500062286854,
      "learning_rate": 2.9156761308025715e-05,
      "loss": 0.0474,
      "step": 1500
    },
    {
      "epoch": 1.3494191242180518,
      "grad_norm": 0.04375398904085159,
      "learning_rate": 2.892588096693889e-05,
      "loss": 0.0062,
      "step": 1510
    },
    {
      "epoch": 1.358355674709562,
      "grad_norm": 0.6718950867652893,
      "learning_rate": 2.8694656805943143e-05,
      "loss": 0.0436,
      "step": 1520
    },
    {
      "epoch": 1.3672922252010724,
      "grad_norm": 4.748254299163818,
      "learning_rate": 2.846310907513536e-05,
      "loss": 0.057,
      "step": 1530
    },
    {
      "epoch": 1.3762287756925826,
      "grad_norm": 0.01155460998415947,
      "learning_rate": 2.823125805294997e-05,
      "loss": 0.021,
      "step": 1540
    },
    {
      "epoch": 1.3851653261840928,
      "grad_norm": 0.005306273233145475,
      "learning_rate": 2.7999124044382975e-05,
      "loss": 0.0566,
      "step": 1550
    },
    {
      "epoch": 1.3941018766756033,
      "grad_norm": 1.7546015977859497,
      "learning_rate": 2.7766727379213686e-05,
      "loss": 0.0475,
      "step": 1560
    },
    {
      "epoch": 1.4030384271671135,
      "grad_norm": 0.00921125989407301,
      "learning_rate": 2.7534088410224302e-05,
      "loss": 0.1136,
      "step": 1570
    },
    {
      "epoch": 1.4119749776586237,
      "grad_norm": 0.24255812168121338,
      "learning_rate": 2.730122751141745e-05,
      "loss": 0.0293,
      "step": 1580
    },
    {
      "epoch": 1.420911528150134,
      "grad_norm": 0.0025429308880120516,
      "learning_rate": 2.7068165076231865e-05,
      "loss": 0.0516,
      "step": 1590
    },
    {
      "epoch": 1.4298480786416443,
      "grad_norm": 0.013944712467491627,
      "learning_rate": 2.6834921515756417e-05,
      "loss": 0.0255,
      "step": 1600
    },
    {
      "epoch": 1.4387846291331545,
      "grad_norm": 0.004706966690719128,
      "learning_rate": 2.6601517256942494e-05,
      "loss": 0.0072,
      "step": 1610
    },
    {
      "epoch": 1.447721179624665,
      "grad_norm": 0.012409755028784275,
      "learning_rate": 2.63679727408151e-05,
      "loss": 0.0403,
      "step": 1620
    },
    {
      "epoch": 1.4566577301161752,
      "grad_norm": 0.005639865528792143,
      "learning_rate": 2.6134308420682667e-05,
      "loss": 0.0271,
      "step": 1630
    },
    {
      "epoch": 1.4655942806076854,
      "grad_norm": 0.006224658340215683,
      "learning_rate": 2.590054476034579e-05,
      "loss": 0.0009,
      "step": 1640
    },
    {
      "epoch": 1.4745308310991958,
      "grad_norm": 0.002497616223990917,
      "learning_rate": 2.5666702232305055e-05,
      "loss": 0.0092,
      "step": 1650
    },
    {
      "epoch": 1.483467381590706,
      "grad_norm": 0.01054016686975956,
      "learning_rate": 2.54328013159681e-05,
      "loss": 0.0956,
      "step": 1660
    },
    {
      "epoch": 1.4924039320822162,
      "grad_norm": 0.014120441861450672,
      "learning_rate": 2.5198862495856106e-05,
      "loss": 0.0378,
      "step": 1670
    },
    {
      "epoch": 1.5013404825737267,
      "grad_norm": 5.076692581176758,
      "learning_rate": 2.4964906259809754e-05,
      "loss": 0.2215,
      "step": 1680
    },
    {
      "epoch": 1.5102770330652369,
      "grad_norm": 0.1384417563676834,
      "learning_rate": 2.4730953097194987e-05,
      "loss": 0.0753,
      "step": 1690
    },
    {
      "epoch": 1.519213583556747,
      "grad_norm": 5.254087924957275,
      "learning_rate": 2.4497023497108575e-05,
      "loss": 0.1723,
      "step": 1700
    },
    {
      "epoch": 1.5281501340482575,
      "grad_norm": 2.6911375522613525,
      "learning_rate": 2.4263137946583743e-05,
      "loss": 0.0883,
      "step": 1710
    },
    {
      "epoch": 1.5370866845397675,
      "grad_norm": 0.11706088483333588,
      "learning_rate": 2.4029316928795958e-05,
      "loss": 0.1625,
      "step": 1720
    },
    {
      "epoch": 1.546023235031278,
      "grad_norm": 2.3286330699920654,
      "learning_rate": 2.3795580921269034e-05,
      "loss": 0.0403,
      "step": 1730
    },
    {
      "epoch": 1.5549597855227884,
      "grad_norm": 0.04770422354340553,
      "learning_rate": 2.3561950394081793e-05,
      "loss": 0.0804,
      "step": 1740
    },
    {
      "epoch": 1.5638963360142983,
      "grad_norm": 0.3560120761394501,
      "learning_rate": 2.332844580807533e-05,
      "loss": 0.045,
      "step": 1750
    },
    {
      "epoch": 1.5728328865058088,
      "grad_norm": 0.013011422008275986,
      "learning_rate": 2.3095087613061058e-05,
      "loss": 0.05,
      "step": 1760
    },
    {
      "epoch": 1.5817694369973192,
      "grad_norm": 0.019210949540138245,
      "learning_rate": 2.2861896246029835e-05,
      "loss": 0.0282,
      "step": 1770
    },
    {
      "epoch": 1.5907059874888292,
      "grad_norm": 0.03543483838438988,
      "learning_rate": 2.2628892129362064e-05,
      "loss": 0.0699,
      "step": 1780
    },
    {
      "epoch": 1.5996425379803396,
      "grad_norm": 0.008250324986875057,
      "learning_rate": 2.239609566903921e-05,
      "loss": 0.0387,
      "step": 1790
    },
    {
      "epoch": 1.6085790884718498,
      "grad_norm": 5.465695858001709,
      "learning_rate": 2.2163527252856614e-05,
      "loss": 0.0394,
      "step": 1800
    },
    {
      "epoch": 1.61751563896336,
      "grad_norm": 0.014459192752838135,
      "learning_rate": 2.193120724863807e-05,
      "loss": 0.0662,
      "step": 1810
    },
    {
      "epoch": 1.6264521894548705,
      "grad_norm": 1.9506605863571167,
      "learning_rate": 2.1699156002451954e-05,
      "loss": 0.1469,
      "step": 1820
    },
    {
      "epoch": 1.6353887399463807,
      "grad_norm": 0.025434400886297226,
      "learning_rate": 2.1467393836829454e-05,
      "loss": 0.0276,
      "step": 1830
    },
    {
      "epoch": 1.6443252904378909,
      "grad_norm": 0.04369828850030899,
      "learning_rate": 2.123594104898471e-05,
      "loss": 0.0588,
      "step": 1840
    },
    {
      "epoch": 1.6532618409294013,
      "grad_norm": 0.6962198615074158,
      "learning_rate": 2.1004817909037245e-05,
      "loss": 0.0458,
      "step": 1850
    },
    {
      "epoch": 1.6621983914209115,
      "grad_norm": 5.384749889373779,
      "learning_rate": 2.0774044658236742e-05,
      "loss": 0.0634,
      "step": 1860
    },
    {
      "epoch": 1.6711349419124217,
      "grad_norm": 0.06667394191026688,
      "learning_rate": 2.0543641507190396e-05,
      "loss": 0.0258,
      "step": 1870
    },
    {
      "epoch": 1.6800714924039322,
      "grad_norm": 0.6396678686141968,
      "learning_rate": 2.0313628634092887e-05,
      "loss": 0.0667,
      "step": 1880
    },
    {
      "epoch": 1.6890080428954424,
      "grad_norm": 0.3472997844219208,
      "learning_rate": 2.0084026182959195e-05,
      "loss": 0.0255,
      "step": 1890
    },
    {
      "epoch": 1.6979445933869526,
      "grad_norm": 0.006939892657101154,
      "learning_rate": 1.9854854261860496e-05,
      "loss": 0.027,
      "step": 1900
    },
    {
      "epoch": 1.706881143878463,
      "grad_norm": 0.00805603712797165,
      "learning_rate": 1.962613294116306e-05,
      "loss": 0.0014,
      "step": 1910
    },
    {
      "epoch": 1.7158176943699732,
      "grad_norm": 0.02468196488916874,
      "learning_rate": 1.9397882251770627e-05,
      "loss": 0.0266,
      "step": 1920
    },
    {
      "epoch": 1.7247542448614834,
      "grad_norm": 0.47273555397987366,
      "learning_rate": 1.9170122183370058e-05,
      "loss": 0.1007,
      "step": 1930
    },
    {
      "epoch": 1.7336907953529939,
      "grad_norm": 0.5375217199325562,
      "learning_rate": 1.8942872682680747e-05,
      "loss": 0.0468,
      "step": 1940
    },
    {
      "epoch": 1.742627345844504,
      "grad_norm": 3.523771286010742,
      "learning_rate": 1.871615365170768e-05,
      "loss": 0.0869,
      "step": 1950
    },
    {
      "epoch": 1.7515638963360143,
      "grad_norm": 0.011472349055111408,
      "learning_rate": 1.8489984945998512e-05,
      "loss": 0.0667,
      "step": 1960
    },
    {
      "epoch": 1.7605004468275247,
      "grad_norm": 0.07758108526468277,
      "learning_rate": 1.8264386372904608e-05,
      "loss": 0.0084,
      "step": 1970
    },
    {
      "epoch": 1.7694369973190347,
      "grad_norm": 0.004535229876637459,
      "learning_rate": 1.8039377689846427e-05,
      "loss": 0.0762,
      "step": 1980
    },
    {
      "epoch": 1.7783735478105451,
      "grad_norm": 0.3167102634906769,
      "learning_rate": 1.7814978602583136e-05,
      "loss": 0.0486,
      "step": 1990
    },
    {
      "epoch": 1.7873100983020556,
      "grad_norm": 0.018017053604125977,
      "learning_rate": 1.7591208763486883e-05,
      "loss": 0.0915,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 3357,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.209493549042893e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
