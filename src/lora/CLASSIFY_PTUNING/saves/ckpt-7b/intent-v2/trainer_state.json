{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 669,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04484304932735426,
      "grad_norm": 19.83407211303711,
      "learning_rate": 4.997244009522703e-05,
      "loss": 6.4156,
      "step": 10
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 6.187367916107178,
      "learning_rate": 4.988982114477616e-05,
      "loss": 1.2825,
      "step": 20
    },
    {
      "epoch": 0.13452914798206278,
      "grad_norm": 11.153125762939453,
      "learning_rate": 4.975232530627998e-05,
      "loss": 0.2714,
      "step": 30
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 0.13586123287677765,
      "learning_rate": 4.956025572951572e-05,
      "loss": 0.1887,
      "step": 40
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 0.036816734820604324,
      "learning_rate": 4.931403588802301e-05,
      "loss": 0.2728,
      "step": 50
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 3.7764859199523926,
      "learning_rate": 4.901420864543265e-05,
      "loss": 0.2309,
      "step": 60
    },
    {
      "epoch": 0.31390134529147984,
      "grad_norm": 32.3805046081543,
      "learning_rate": 4.866143505856496e-05,
      "loss": 0.0817,
      "step": 70
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.008559739217162132,
      "learning_rate": 4.825649291993677e-05,
      "loss": 0.2179,
      "step": 80
    },
    {
      "epoch": 0.40358744394618834,
      "grad_norm": 1.4582287073135376,
      "learning_rate": 4.780027504289042e-05,
      "loss": 0.0779,
      "step": 90
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 20.86387825012207,
      "learning_rate": 4.729378729312569e-05,
      "loss": 0.3093,
      "step": 100
    },
    {
      "epoch": 0.49327354260089684,
      "grad_norm": 2.550739288330078,
      "learning_rate": 4.673814637097475e-05,
      "loss": 0.0321,
      "step": 110
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 2.7624011039733887,
      "learning_rate": 4.613457734930978e-05,
      "loss": 0.0798,
      "step": 120
    },
    {
      "epoch": 0.5829596412556054,
      "grad_norm": 0.007459266576915979,
      "learning_rate": 4.5484410972511685e-05,
      "loss": 0.0034,
      "step": 130
    },
    {
      "epoch": 0.6278026905829597,
      "grad_norm": 11.661380767822266,
      "learning_rate": 4.4789080722454946e-05,
      "loss": 0.0134,
      "step": 140
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 0.5675119757652283,
      "learning_rate": 4.405011965797775e-05,
      "loss": 0.0801,
      "step": 150
    },
    {
      "epoch": 0.7174887892376681,
      "grad_norm": 1.1644928455352783,
      "learning_rate": 4.3269157034805524e-05,
      "loss": 0.0276,
      "step": 160
    },
    {
      "epoch": 0.7623318385650224,
      "grad_norm": 72.63775634765625,
      "learning_rate": 4.244791471338035e-05,
      "loss": 0.2613,
      "step": 170
    },
    {
      "epoch": 0.8071748878923767,
      "grad_norm": 0.17584241926670074,
      "learning_rate": 4.1588203362516153e-05,
      "loss": 0.1305,
      "step": 180
    },
    {
      "epoch": 0.852017937219731,
      "grad_norm": 0.17267711460590363,
      "learning_rate": 4.069191846724989e-05,
      "loss": 0.0003,
      "step": 190
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.007039027754217386,
      "learning_rate": 3.9761036149690596e-05,
      "loss": 0.123,
      "step": 200
    },
    {
      "epoch": 0.9417040358744395,
      "grad_norm": 0.1184421107172966,
      "learning_rate": 3.879760881208042e-05,
      "loss": 0.0028,
      "step": 210
    },
    {
      "epoch": 0.9865470852017937,
      "grad_norm": 0.004988625179976225,
      "learning_rate": 3.780376061167379e-05,
      "loss": 0.0538,
      "step": 220
    },
    {
      "epoch": 1.031390134529148,
      "grad_norm": 0.006272368598729372,
      "learning_rate": 3.678168277741166e-05,
      "loss": 0.0242,
      "step": 230
    },
    {
      "epoch": 1.0762331838565022,
      "grad_norm": 0.010444997809827328,
      "learning_rate": 3.5733628778716646e-05,
      "loss": 0.0005,
      "step": 240
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.008434703573584557,
      "learning_rate": 3.4661909357060836e-05,
      "loss": 0.0001,
      "step": 250
    },
    {
      "epoch": 1.1659192825112108,
      "grad_norm": 0.0021780517417937517,
      "learning_rate": 3.3568887431260565e-05,
      "loss": 0.0001,
      "step": 260
    },
    {
      "epoch": 1.210762331838565,
      "grad_norm": 0.0020849702414125204,
      "learning_rate": 3.245697288773102e-05,
      "loss": 0.0566,
      "step": 270
    },
    {
      "epoch": 1.2556053811659194,
      "grad_norm": 0.001734103192575276,
      "learning_rate": 3.132861726718702e-05,
      "loss": 0.0045,
      "step": 280
    },
    {
      "epoch": 1.3004484304932735,
      "grad_norm": 0.021162310615181923,
      "learning_rate": 3.0186308359504765e-05,
      "loss": 0.0065,
      "step": 290
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.0013200783869251609,
      "learning_rate": 2.9032564718661603e-05,
      "loss": 0.0751,
      "step": 300
    },
    {
      "epoch": 1.390134529147982,
      "grad_norm": 0.0018261505756527185,
      "learning_rate": 2.786993010984747e-05,
      "loss": 0.0001,
      "step": 310
    },
    {
      "epoch": 1.4349775784753362,
      "grad_norm": 0.0031319137196987867,
      "learning_rate": 2.6700967900990732e-05,
      "loss": 0.1617,
      "step": 320
    },
    {
      "epoch": 1.4798206278026906,
      "grad_norm": 0.004473602864891291,
      "learning_rate": 2.552825541106414e-05,
      "loss": 0.0001,
      "step": 330
    },
    {
      "epoch": 1.5246636771300448,
      "grad_norm": 0.003305973717942834,
      "learning_rate": 2.4354378227631565e-05,
      "loss": 0.1324,
      "step": 340
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 0.06598452478647232,
      "learning_rate": 2.318192450616426e-05,
      "loss": 0.0005,
      "step": 350
    },
    {
      "epoch": 1.6143497757847534,
      "grad_norm": 0.009111646562814713,
      "learning_rate": 2.2013479263695368e-05,
      "loss": 0.0105,
      "step": 360
    },
    {
      "epoch": 1.6591928251121075,
      "grad_norm": 0.004081003367900848,
      "learning_rate": 2.085161867939409e-05,
      "loss": 0.008,
      "step": 370
    },
    {
      "epoch": 1.704035874439462,
      "grad_norm": 0.001876737573184073,
      "learning_rate": 1.969890441462544e-05,
      "loss": 0.0002,
      "step": 380
    },
    {
      "epoch": 1.7488789237668163,
      "grad_norm": 0.002199253998696804,
      "learning_rate": 1.8557877965018817e-05,
      "loss": 0.1595,
      "step": 390
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 0.005545014515519142,
      "learning_rate": 1.7431055056997803e-05,
      "loss": 0.1096,
      "step": 400
    },
    {
      "epoch": 1.8385650224215246,
      "grad_norm": 0.004611440934240818,
      "learning_rate": 1.632092010112567e-05,
      "loss": 0.0361,
      "step": 410
    },
    {
      "epoch": 1.883408071748879,
      "grad_norm": 0.004315261263400316,
      "learning_rate": 1.5229920714495948e-05,
      "loss": 0.0134,
      "step": 420
    },
    {
      "epoch": 1.9282511210762332,
      "grad_norm": 0.00238642655313015,
      "learning_rate": 1.4160462324244863e-05,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 1.9730941704035874,
      "grad_norm": 0.011764262802898884,
      "learning_rate": 1.3114902864083933e-05,
      "loss": 0.0002,
      "step": 440
    },
    {
      "epoch": 2.0179372197309418,
      "grad_norm": 7.627577781677246,
      "learning_rate": 1.2095547575545686e-05,
      "loss": 0.0024,
      "step": 450
    },
    {
      "epoch": 2.062780269058296,
      "grad_norm": 0.0025695553049445152,
      "learning_rate": 1.1104643925404679e-05,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 2.10762331838565,
      "grad_norm": 0.006224159151315689,
      "learning_rate": 1.0144376650479867e-05,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 2.1524663677130045,
      "grad_norm": 0.013555080629885197,
      "learning_rate": 9.216862940743529e-06,
      "loss": 0.0002,
      "step": 480
    },
    {
      "epoch": 2.197309417040359,
      "grad_norm": 0.0035340527538210154,
      "learning_rate": 8.324147771356963e-06,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 2.242152466367713,
      "grad_norm": 0.0024421040434390306,
      "learning_rate": 7.468199393924774e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 2.286995515695067,
      "grad_norm": 0.0020702537149190903,
      "learning_rate": 6.6509049969087715e-06,
      "loss": 0.0051,
      "step": 510
    },
    {
      "epoch": 2.3318385650224216,
      "grad_norm": 0.008478790521621704,
      "learning_rate": 5.874066544769216e-06,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 2.376681614349776,
      "grad_norm": 0.010956785641610622,
      "learning_rate": 5.139396805007307e-06,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 2.42152466367713,
      "grad_norm": 0.033941853791475296,
      "learning_rate": 4.448515571868434e-06,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 2.4663677130044843,
      "grad_norm": 0.0024298529606312513,
      "learning_rate": 3.8029460950321784e-06,
      "loss": 0.1156,
      "step": 550
    },
    {
      "epoch": 2.5112107623318387,
      "grad_norm": 0.0031500584445893764,
      "learning_rate": 3.2041117211630166e-06,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 2.5560538116591927,
      "grad_norm": 0.011398746632039547,
      "learning_rate": 2.65333275572644e-06,
      "loss": 0.0658,
      "step": 570
    },
    {
      "epoch": 2.600896860986547,
      "grad_norm": 0.0018333351472392678,
      "learning_rate": 2.151823551989518e-06,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 2.6457399103139014,
      "grad_norm": 0.009276648983359337,
      "learning_rate": 1.7006898336240722e-06,
      "loss": 0.1144,
      "step": 590
    },
    {
      "epoch": 2.6905829596412554,
      "grad_norm": 0.0016995060723274946,
      "learning_rate": 1.300926256815546e-06,
      "loss": 0.0003,
      "step": 600
    },
    {
      "epoch": 2.7354260089686098,
      "grad_norm": 0.0017185065662488341,
      "learning_rate": 9.534142172526239e-07,
      "loss": 0.0458,
      "step": 610
    },
    {
      "epoch": 2.780269058295964,
      "grad_norm": 0.0018295797053724527,
      "learning_rate": 6.589199068327279e-07,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 2.8251121076233185,
      "grad_norm": 0.002383948303759098,
      "learning_rate": 4.180926243679689e-07,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 2.8699551569506725,
      "grad_norm": 15.696019172668457,
      "learning_rate": 2.3146334401606408e-07,
      "loss": 0.0863,
      "step": 640
    },
    {
      "epoch": 2.914798206278027,
      "grad_norm": 0.0026218092534691095,
      "learning_rate": 9.944354459256178e-08,
      "loss": 0.1235,
      "step": 650
    },
    {
      "epoch": 2.9596412556053813,
      "grad_norm": 0.12605614960193634,
      "learning_rate": 2.2324302345483327e-08,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 3.0,
      "step": 669,
      "total_flos": 3.3748898840838144e+16,
      "train_loss": 0.17215782041953437,
      "train_runtime": 3488.5757,
      "train_samples_per_second": 0.765,
      "train_steps_per_second": 0.192
    }
  ],
  "logging_steps": 10,
  "max_steps": 669,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.3748898840838144e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
